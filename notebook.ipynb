{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7DZa4UUDNw2"
   },
   "source": [
    "# Wind Power forecasting for the day-ahead energy market - Data Challenge\n",
    "by Compagnie Nationale du Rhône, ENS Paris & Collège de France\n",
    "\n",
    "<p align=\"center\"><img src=\"https://cap.img.pmdstatic.net/fit/http.3A.2F.2Fprd2-bone-image.2Es3-website-eu-west-1.2Eamazonaws.2Ecom.2Fcap.2F2019.2F10.2F04.2Fea495374-9115-4be7-a91a-e9bc5b305b0b.2Ejpeg/768x432/background-color/ffffff/focus-point/992%2C1086/quality/70/dangereuses-pour-la-sante-peu-ecolo-faut-il-en-finir-avec-les-eoliennes-1352031.jpg\" width=\"600\"/></p>\n",
    "\n",
    "Challenge website: https://challengedata.ens.fr/participants/challenges/34/\n",
    "\n",
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvtF7nQATbmR"
   },
   "outputs": [],
   "source": [
    "# For personal Google Colab configuration only, please skip this cell.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "%cd /content/gdrive/MyDrive/wind-power-forecasting-challenge\n",
    "!pip install urllib3==1.25.4 folium==0.2.1 boto3 mlflow mpld3 --quiet\n",
    "import pandas as pd\n",
    "import os, mlflow\n",
    "cred = pd.read_csv('aws_credentials.csv',index_col=0, squeeze=True)\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = cred.AWS_ACCESS_KEY_ID\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = cred.AWS_SECRET_ACCESS_KEY\n",
    "mlflow.set_tracking_uri(f\"http://{cred.AWS_USERNAME}:{cred.AWS_PASSWORD}@{cred.AWS_URL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 22601,
     "status": "ok",
     "timestamp": 1612551946501,
     "user": {
      "displayName": "Quentin Chateiller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguKgZaCTK0rxnxTJIqcAU2_SCRshI2HzPX7stG7AY=s64",
      "userId": "11797464397335309536"
     },
     "user_tz": -60
    },
    "id": "hf8u3qX7DNw4"
   },
   "outputs": [],
   "source": [
    "# Load and configure libraires\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import importlib\n",
    "import core\n",
    "import mlflow, mlflow.tensorflow\n",
    "import mpld3\n",
    "import os\n",
    "import pandas as pd\n",
    "mlflow.tensorflow.autolog(every_n_iter=1,log_models=False)\n",
    "mpld3.enable_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unrWlVffDNw5"
   },
   "source": [
    "## Challenge presentation\n",
    "\n",
    "The objective of this challenge is to design and train an ML/DL model to predict the hourly electrical production of six independent wind farms owned by CNR for the day ahead, using multiple Numerical Weather Predictions (NWP) models.\n",
    "\n",
    "## Data\n",
    "### First exploration\n",
    "\n",
    "In this challenge, we are provided with a **training dataset** and a **test dataset**.\n",
    "\n",
    "The **training dataset** is composed of different hourly weather forecasts (X) for a period of 8 consecutive months (from May the 1st of 2018 to January the 15th of 2019), together with the associated observed power production in MW (Y). In the **test dataset**, only predictions are provided for another period of 8 months (January the 16th of 2019 to September the 30rd of 2019). The performance of our model is then evaluated online, by submitting its predictions on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TZ-PrOMhDNw5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WF</th>\n",
       "      <th>Time</th>\n",
       "      <th>NWP1_00h_D-2_U</th>\n",
       "      <th>NWP1_00h_D-2_V</th>\n",
       "      <th>NWP1_00h_D-2_T</th>\n",
       "      <th>NWP1_06h_D-2_U</th>\n",
       "      <th>NWP1_06h_D-2_V</th>\n",
       "      <th>NWP1_06h_D-2_T</th>\n",
       "      <th>NWP1_12h_D-2_U</th>\n",
       "      <th>NWP1_12h_D-2_V</th>\n",
       "      <th>...</th>\n",
       "      <th>NWP4_12h_D-1_U</th>\n",
       "      <th>NWP4_12h_D-1_V</th>\n",
       "      <th>NWP4_12h_D-1_CLCT</th>\n",
       "      <th>NWP4_00h_D_U</th>\n",
       "      <th>NWP4_00h_D_V</th>\n",
       "      <th>NWP4_00h_D_CLCT</th>\n",
       "      <th>NWP4_12h_D_U</th>\n",
       "      <th>NWP4_12h_D_V</th>\n",
       "      <th>NWP4_12h_D_CLCT</th>\n",
       "      <th>Production</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10017</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-10-05 10:00:00</td>\n",
       "      <td>-2.4174</td>\n",
       "      <td>4.3334</td>\n",
       "      <td>292.91</td>\n",
       "      <td>-1.1047</td>\n",
       "      <td>4.2202</td>\n",
       "      <td>293.11</td>\n",
       "      <td>-1.4876</td>\n",
       "      <td>4.5239</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.116280</td>\n",
       "      <td>3.619540</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>-0.951876</td>\n",
       "      <td>3.449261</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34684</th>\n",
       "      <td>6</td>\n",
       "      <td>2018-09-25 20:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5862</td>\n",
       "      <td>-6.1266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721509</td>\n",
       "      <td>-1.190149</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.597763</td>\n",
       "      <td>-1.212407</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.554162</td>\n",
       "      <td>-1.325859</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66449</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-08-09 08:00:00</td>\n",
       "      <td>2.8611</td>\n",
       "      <td>6.9973</td>\n",
       "      <td>293.81</td>\n",
       "      <td>1.1254</td>\n",
       "      <td>8.5300</td>\n",
       "      <td>294.39</td>\n",
       "      <td>0.4473</td>\n",
       "      <td>8.3214</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34860</th>\n",
       "      <td>6</td>\n",
       "      <td>2018-10-03 04:00:00</td>\n",
       "      <td>-0.9959</td>\n",
       "      <td>-8.4966</td>\n",
       "      <td>284.96</td>\n",
       "      <td>-1.1464</td>\n",
       "      <td>-9.0395</td>\n",
       "      <td>284.31</td>\n",
       "      <td>-1.9634</td>\n",
       "      <td>-9.1864</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.373555</td>\n",
       "      <td>-4.744170</td>\n",
       "      <td>86.145910</td>\n",
       "      <td>-1.133010</td>\n",
       "      <td>-4.015365</td>\n",
       "      <td>85.622509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62832</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-02-15 04:00:00</td>\n",
       "      <td>-2.9261</td>\n",
       "      <td>10.2940</td>\n",
       "      <td>275.77</td>\n",
       "      <td>0.3523</td>\n",
       "      <td>7.1205</td>\n",
       "      <td>274.78</td>\n",
       "      <td>-1.4186</td>\n",
       "      <td>7.8341</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       WF                Time  NWP1_00h_D-2_U  NWP1_00h_D-2_V  NWP1_00h_D-2_T  \\\n",
       "ID                                                                              \n",
       "10017   2 2018-10-05 10:00:00         -2.4174          4.3334          292.91   \n",
       "34684   6 2018-09-25 20:00:00             NaN             NaN             NaN   \n",
       "66449   5 2019-08-09 08:00:00          2.8611          6.9973          293.81   \n",
       "34860   6 2018-10-03 04:00:00         -0.9959         -8.4966          284.96   \n",
       "62832   5 2019-02-15 04:00:00         -2.9261         10.2940          275.77   \n",
       "\n",
       "       NWP1_06h_D-2_U  NWP1_06h_D-2_V  NWP1_06h_D-2_T  NWP1_12h_D-2_U  \\\n",
       "ID                                                                      \n",
       "10017         -1.1047          4.2202          293.11         -1.4876   \n",
       "34684             NaN             NaN             NaN          1.5862   \n",
       "66449          1.1254          8.5300          294.39          0.4473   \n",
       "34860         -1.1464         -9.0395          284.31         -1.9634   \n",
       "62832          0.3523          7.1205          274.78         -1.4186   \n",
       "\n",
       "       NWP1_12h_D-2_V  ...  NWP4_12h_D-1_U  NWP4_12h_D-1_V  NWP4_12h_D-1_CLCT  \\\n",
       "ID                     ...                                                      \n",
       "10017          4.5239  ...       -1.116280        3.619540          -0.000023   \n",
       "34684         -6.1266  ...        0.721509       -1.190149          -0.000022   \n",
       "66449          8.3214  ...             NaN             NaN                NaN   \n",
       "34860         -9.1864  ...       -0.373555       -4.744170          86.145910   \n",
       "62832          7.8341  ...             NaN             NaN                NaN   \n",
       "\n",
       "       NWP4_00h_D_U  NWP4_00h_D_V  NWP4_00h_D_CLCT  NWP4_12h_D_U  \\\n",
       "ID                                                                 \n",
       "10017     -0.951876      3.449261        -0.000022           NaN   \n",
       "34684      0.597763     -1.212407        -0.000018      0.554162   \n",
       "66449           NaN           NaN              NaN           NaN   \n",
       "34860     -1.133010     -4.015365        85.622509           NaN   \n",
       "62832           NaN           NaN              NaN           NaN   \n",
       "\n",
       "       NWP4_12h_D_V  NWP4_12h_D_CLCT  Production  \n",
       "ID                                                \n",
       "10017           NaN              NaN        0.42  \n",
       "34684     -1.325859        -0.000023        0.61  \n",
       "66449           NaN              NaN         NaN  \n",
       "34860           NaN              NaN        2.22  \n",
       "62832           NaN              NaN         NaN  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = core.load_data()\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **training example** is thus associated to the power production (*Production* column) of one of the six considered wind farms (*WF* column) at a given date and time (*Time* column). For a given couple (*WF*, *Time*), we then have several weather forecasts (*NWP\\<i>_\\<HourOfTheRun>_\\<DayOfTheRun>_\\<Variable>* columns), each of them giving an estimation of a particular weather *Variable*, produced at different times (*HourOfTheRun*, *DayOfTheRun*) before the target *Time*, and coming from different NWP models (*i*). For instance, the run *NWP1_00h_D-2_U* is estimating the weather variable *U* for a given target *Time* using the first NWP model, and is produced at midnight two days before this target *Time*.\n",
    "\n",
    "The runs are coming from 4 different NWP models ($i\\in[1,4]$), and are forecasting 4 weather variables at various time:\n",
    " \n",
    "NWP Variable | Prediction description | NWP 1 (hourly) | NWP 2 (every 3 hours) | NWP 3 (every 3 hours) | NWP 4 (hourly)\n",
    "------ | ----- | ----- | ----- | ----- | -----\n",
    "Wind speed U,V (m/s) | 10min average [H-10min,H] | x (@100m) | x (@100m) | x (@100m) | x (@10m)\n",
    "Temperature of air T (m/s) | 1hour average [H-1,H] | x |  | x |\n",
    "Total cloud cover CLCT (%) | instant value at H | | | | x\n",
    "\n",
    "Further details about these forecasts wan be found on the challenge webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WV8JmIjrc_wO"
   },
   "outputs": [],
   "source": [
    "# Data parameters\r\n",
    "FORECAST_MEMORY = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DqDy19JNDNw6"
   },
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "df = utilities.calculate_best_forecasts(df, FORECAST_MEMORY)\n",
    "df = utilities.interpolate_nans(df)\n",
    "df = utilities.augment_data(df)\n",
    "df = utilities.normalize_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piGHgpwSDNw6"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gYtVmg6WdGjc"
   },
   "outputs": [],
   "source": [
    "# Model parameters\r\n",
    "WINDOW_SIZE = 72  # In hours\r\n",
    "BATCH_SIZE = 2000\r\n",
    "EPOCHS = 10\r\n",
    "UNITS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mF1wTcwTDNw6"
   },
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(t_train, x_train, y_train, t_valid, x_valid, y_valid):\n",
    "\n",
    "    mlflow.log_params({'window_size':WINDOW_SIZE, 'units':UNITS, 'layer_type':'GRU'})\n",
    "    \n",
    "    # Make learning datasets\n",
    "    dataset_train = utilities.get_windowed_dataset(x_train, y_train, WINDOW_SIZE, BATCH_SIZE, shuffle=True)\n",
    "    dataset_valid = utilities.get_windowed_dataset(x_valid, y_valid, WINDOW_SIZE, BATCH_SIZE, shuffle=False) if x_valid is not None else None\n",
    "        \n",
    "    # Define model\n",
    "    model = tf.keras.Sequential([\n",
    "                tf.keras.layers.InputLayer(input_shape=next(iter(dataset_train))[0].shape[1:]),\n",
    "                tf.keras.layers.GRU(UNITS, return_sequences=True),\n",
    "                tf.keras.layers.Dropout(0.6),\n",
    "                tf.keras.layers.GRU(UNITS, return_sequences=True),\n",
    "                tf.keras.layers.Dropout(0.6),\n",
    "                tf.keras.layers.GRU(UNITS),\n",
    "                tf.keras.layers.Dense(1, activation='relu')\n",
    "            ])\n",
    "    model.compile(loss='mse', \n",
    "                  optimizer=tf.keras.optimizers.Adam())\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(dataset_train, \n",
    "                        validation_data=dataset_valid,\n",
    "                        epochs=EPOCHS,\n",
    "                        verbose=1, \n",
    "                        callbacks=[])#tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.00001,patience=30)])\n",
    "    utilities.plot_learning_curves(history)\n",
    "    \n",
    "    # Check predictions\n",
    "    y_train_predict = utilities.predict(model, dataset_train, t_train)\n",
    "    utilities.plot_predictions(t_train, y_train, y_train_predict, 'train')\n",
    "    if dataset_valid is not None :\n",
    "        y_valid_predict = utilities.predict(model, dataset_valid, t_valid)\n",
    "        utilities.plot_predictions(t_valid, y_valid, y_valid_predict, 'valid')\n",
    "            \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7l1P4URCZrUT"
   },
   "source": [
    "# Holdout validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HN6vRa-rdZcl"
   },
   "outputs": [],
   "source": [
    "HOLDOUT_VAL_SPLIT = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08_Y_Us5DNw6"
   },
   "outputs": [],
   "source": [
    "# TRAIN ONLY ONE WIND FARM\n",
    "# ================================\n",
    "def train_holdout_validation(wf_num, nested_run=False) :\n",
    "\n",
    "    with mlflow.start_run(nested=nested_run):    \n",
    "        mlflow.log_params({'wf':wf_num, 'split':HOLDOUT_VAL_SPLIT})\n",
    "\n",
    "        # Extract wf data\n",
    "        df_wf = utilities.extract_wf_data(df, wf_num)\n",
    "        \n",
    "        # Train\n",
    "        t_train, x_train, y_train, t_valid, x_valid, y_valid = utilities.split_holdout_validation(df_wf, HOLDOUT_VAL_SPLIT, WINDOW_SIZE)\n",
    "        model, history = train_model(t_train, x_train, y_train, t_valid, x_valid, y_valid)\n",
    "            \n",
    "    return model, history    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50QVcEqgzlzc"
   },
   "outputs": [],
   "source": [
    "# Train one wind farm\n",
    "mlflow.set_experiment('holdout_validation')\n",
    "model, history = train_holdout_validation(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rY_7A48AOMCF"
   },
   "outputs": [],
   "source": [
    "# Train all wind farms\n",
    "mlflow.set_experiment('holdout_validation')\n",
    "with mlflow.start_run() :\n",
    "    for wf_num in df.WF.unique(): \n",
    "        train_holdout_validation(wf_num, nested_run = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4xRxSDtv0e3"
   },
   "source": [
    "# Forward chaining validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JoLW8rJ7d-Fg"
   },
   "outputs": [],
   "source": [
    "# Forward chaining parameters\r\n",
    "FC_VAL_NB = 4\r\n",
    "FC_VAL_SIZE = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qdriGb82v0e3"
   },
   "outputs": [],
   "source": [
    "def train_forward_chaining_validation(wf_num):\n",
    "\n",
    "    # Extract wf data\n",
    "    df_wf = utilities.extract_wf_data(df, wf_num)\n",
    "    \n",
    "    # Train models\n",
    "    metrics = []\n",
    "    datas = utilities.split_forward_chaining_validation(df_wf, FC_VAL_SIZE, FC_VAL_NB, WINDOW_SIZE)\n",
    "    for (t_train, x_train, y_train, t_valid, x_valid, y_valid) in datas :\n",
    "        with mlflow.start_run(nested=True) :\n",
    "            model, history = train_model(t_train, x_train, y_train, t_valid, x_valid, y_valid)\n",
    "            metrics.append(history.history)\n",
    "    \n",
    "    # Calculate mean and std errors\n",
    "    metrics = utilities.get_mean_std_metrics(metrics)\n",
    "    mlflow.log_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKdYEe9Ox1k_"
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment('forward_chaining_validation')\n",
    "for wf_num in df.WF.unique():\n",
    "    with mlflow.start_run():    \n",
    "        mlflow.log_params({'wf':wf_num,'valid_size':FC_VAL_SIZE,'nb_valid':FC_VAL_NB, 'nlayers':3, \n",
    "                        'layer_type':'GRU','units':UNITS,'epochs':EPOCHS, 'parent':True})\n",
    "        train_forward_chaining_validation(wf_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jC0ea6kQgr1J"
   },
   "outputs": [],
   "source": [
    "wf_num = 4\r\n",
    "mlflow.set_experiment('forward_chaining_validation')\r\n",
    "for UNITS in [32,64] :\r\n",
    "    with mlflow.start_run() :\r\n",
    "        mlflow.log_params({'wf':wf_num,'valid_size':FC_VAL_SIZE,'nb_valid':FC_VAL_NB, 'nlayers':1, \r\n",
    "                           'layer_type':'GRU', 'units':UNITS, 'epochs':EPOCHS, 'parent':True })\r\n",
    "        train_forward_chaining_validation(wf_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PK3nZypssKI2"
   },
   "source": [
    "# Full training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m6SuOmlPDNw7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TRAIN ALL WIND FARMS AND PREDICT\n",
    "# ================================\n",
    "def train_full(wf_num, nested_run=False) :\n",
    "    with mlflow.start_run(nested=nested_run): \n",
    "        mlflow.log_param('wf',wf_num)\n",
    "\n",
    "        # Extract data\n",
    "        df_wf = utilities.extract_wf_data(df, wf_num)        \n",
    "        \n",
    "        # Train model\n",
    "        t_train, x_train, y_train = utilities.get_train_dataset(df_wf, WINDOW_SIZE)\n",
    "        model, history = train_model(t_train, x_train, y_train, None, None, None)\n",
    "\n",
    "        # Predict on test data\n",
    "        t_test, x_test = utilities.get_test_dataset(df_wf, WINDOW_SIZE)\n",
    "        dataset_test = utilities.get_windowed_dataset(x_test, None, WINDOW_SIZE, BATCH_SIZE, shuffle=False)\n",
    "        y_test_predict = utilities.predict(model, dataset_test, t_test)    \n",
    "        utilities.plot_predictions(t_test, None, y_test_predict, 'test')\n",
    "\n",
    "    return y_test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "67BQ2u3Azlzh"
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment('Full training')\n",
    "with mlflow.start_run():\n",
    "    predictions = [train_full(wf_num, nested_run=True) for wf_num in df.WF.unique()]\n",
    "    utilities.save_predictions(predictions)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lstm_testsetval.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "wind-power-forecasting-challenge",
   "language": "python",
   "name": "wind-power-forecasting-challenge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
