{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"lstm_testsetval.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"wind-power-forecasting-challenge","language":"python","name":"wind-power-forecasting-challenge"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Q7DZa4UUDNw2"},"source":["# Initialization"]},{"cell_type":"code","metadata":{"id":"gvtF7nQATbmR"},"source":["# Google Colab config\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd /content/gdrive/MyDrive/wind-power-forecasting-challenge\n","!pip install urllib3==1.25.4 folium==0.2.1 boto3 mlflow mpld3 --quiet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hf8u3qX7DNw4","executionInfo":{"status":"ok","timestamp":1612551946501,"user_tz":-60,"elapsed":22601,"user":{"displayName":"Quentin Chateiller","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguKgZaCTK0rxnxTJIqcAU2_SCRshI2HzPX7stG7AY=s64","userId":"11797464397335309536"}}},"source":["# Load libraires\n","import pandas as pd\n","import tensorflow as tf\n","import importlib\n","import utilities\n","import mlflow\n","import mlflow.tensorflow\n","import mpld3\n","import os\n","import pandas as pd\n","cred = pd.read_csv('aws_credentials.csv',index_col=0, squeeze=True)\n","os.environ['AWS_ACCESS_KEY_ID'] = cred.AWS_ACCESS_KEY_ID\n","os.environ['AWS_SECRET_ACCESS_KEY'] = cred.AWS_SECRET_ACCESS_KEY\n","mlflow.set_tracking_uri(f\"http://{cred.AWS_USERNAME}:{cred.AWS_PASSWORD}@{cred.AWS_URL}\")\n","mlflow.tensorflow.autolog(every_n_iter=1,log_models=False)\n","mpld3.enable_notebook()"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"unrWlVffDNw5"},"source":["# Data"]},{"cell_type":"code","metadata":{"id":"WV8JmIjrc_wO"},"source":["# Data parameters\r\n","FORECAST_MEMORY = 0.9"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TZ-PrOMhDNw5"},"source":["# Load data\n","df = utilities.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DqDy19JNDNw6"},"source":["# Preprocess data\n","df = utilities.calculate_best_forecasts(df, FORECAST_MEMORY)\n","df = utilities.interpolate_nans(df)\n","df = utilities.augment_data(df)\n","df = utilities.normalize_data(df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"piGHgpwSDNw6"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"gYtVmg6WdGjc"},"source":["# Model parameters\r\n","WINDOW_SIZE = 72  # In hours\r\n","BATCH_SIZE = 2000\r\n","EPOCHS = 10\r\n","UNITS = 32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mF1wTcwTDNw6"},"source":["# Training function\n","def train_model(t_train, x_train, y_train, t_valid, x_valid, y_valid):\n","\n","    mlflow.log_params({'window_size':WINDOW_SIZE, 'units':UNITS, 'layer_type':'GRU'})\n","    \n","    # Make learning datasets\n","    dataset_train = utilities.get_windowed_dataset(x_train, y_train, WINDOW_SIZE, BATCH_SIZE, shuffle=True)\n","    dataset_valid = utilities.get_windowed_dataset(x_valid, y_valid, WINDOW_SIZE, BATCH_SIZE, shuffle=False) if x_valid is not None else None\n","        \n","    # Define model\n","    model = tf.keras.Sequential([\n","                tf.keras.layers.InputLayer(input_shape=next(iter(dataset_train))[0].shape[1:]),\n","                tf.keras.layers.GRU(UNITS, return_sequences=True),\n","                tf.keras.layers.Dropout(0.6),\n","                tf.keras.layers.GRU(UNITS, return_sequences=True),\n","                tf.keras.layers.Dropout(0.6),\n","                tf.keras.layers.GRU(UNITS),\n","                tf.keras.layers.Dense(1, activation='relu')\n","            ])\n","    model.compile(loss='mse', \n","                  optimizer=tf.keras.optimizers.Adam())\n","    \n","    # Train model\n","    history = model.fit(dataset_train, \n","                        validation_data=dataset_valid,\n","                        epochs=EPOCHS,\n","                        verbose=1, \n","                        callbacks=[])#tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.00001,patience=30)])\n","    utilities.plot_learning_curves(history)\n","    \n","    # Check predictions\n","    y_train_predict = utilities.predict(model, dataset_train, t_train)\n","    utilities.plot_predictions(t_train, y_train, y_train_predict, 'train')\n","    if dataset_valid is not None :\n","        y_valid_predict = utilities.predict(model, dataset_valid, t_valid)\n","        utilities.plot_predictions(t_valid, y_valid, y_valid_predict, 'valid')\n","            \n","    return model, history"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7l1P4URCZrUT"},"source":["# Holdout validation"]},{"cell_type":"code","metadata":{"id":"HN6vRa-rdZcl"},"source":["HOLDOUT_VAL_SPLIT = 0.85"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"08_Y_Us5DNw6"},"source":["# TRAIN ONLY ONE WIND FARM\n","# ================================\n","def train_holdout_validation(wf_num, nested_run=False) :\n","\n","    with mlflow.start_run(nested=nested_run):    \n","        mlflow.log_params({'wf':wf_num, 'split':HOLDOUT_VAL_SPLIT})\n","\n","        # Extract wf data\n","        df_wf = utilities.extract_wf_data(df, wf_num)\n","        \n","        # Train\n","        t_train, x_train, y_train, t_valid, x_valid, y_valid = utilities.split_holdout_validation(df_wf, HOLDOUT_VAL_SPLIT, WINDOW_SIZE)\n","        model, history = train_model(t_train, x_train, y_train, t_valid, x_valid, y_valid)\n","            \n","    return model, history    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"50QVcEqgzlzc"},"source":["# Train one wind farm\n","mlflow.set_experiment('holdout_validation')\n","model, history = train_holdout_validation(3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rY_7A48AOMCF"},"source":["# Train all wind farms\n","mlflow.set_experiment('holdout_validation')\n","with mlflow.start_run() :\n","    for wf_num in df.WF.unique(): \n","        train_holdout_validation(wf_num, nested_run = True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o4xRxSDtv0e3"},"source":["# Forward chaining validation"]},{"cell_type":"code","metadata":{"id":"JoLW8rJ7d-Fg"},"source":["# Forward chaining parameters\r\n","FC_VAL_NB = 4\r\n","FC_VAL_SIZE = 0.05"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qdriGb82v0e3"},"source":["def train_forward_chaining_validation(wf_num):\n","\n","    # Extract wf data\n","    df_wf = utilities.extract_wf_data(df, wf_num)\n","    \n","    # Train models\n","    metrics = []\n","    datas = utilities.split_forward_chaining_validation(df_wf, FC_VAL_SIZE, FC_VAL_NB, WINDOW_SIZE)\n","    for (t_train, x_train, y_train, t_valid, x_valid, y_valid) in datas :\n","        with mlflow.start_run(nested=True) :\n","            model, history = train_model(t_train, x_train, y_train, t_valid, x_valid, y_valid)\n","            metrics.append(history.history)\n","    \n","    # Calculate mean and std errors\n","    metrics = utilities.get_mean_std_metrics(metrics)\n","    mlflow.log_metrics(metrics)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nKdYEe9Ox1k_"},"source":["mlflow.set_experiment('forward_chaining_validation')\n","for wf_num in df.WF.unique():\n","    with mlflow.start_run():    \n","        mlflow.log_params({'wf':wf_num,'valid_size':FC_VAL_SIZE,'nb_valid':FC_VAL_NB, 'nlayers':3, \n","                        'layer_type':'GRU','units':UNITS,'epochs':EPOCHS, 'parent':True})\n","        train_forward_chaining_validation(wf_num)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jC0ea6kQgr1J"},"source":["wf_num = 4\r\n","mlflow.set_experiment('forward_chaining_validation')\r\n","for UNITS in [32,64] :\r\n","    with mlflow.start_run() :\r\n","        mlflow.log_params({'wf':wf_num,'valid_size':FC_VAL_SIZE,'nb_valid':FC_VAL_NB, 'nlayers':1, \r\n","                           'layer_type':'GRU', 'units':UNITS, 'epochs':EPOCHS, 'parent':True })\r\n","        train_forward_chaining_validation(wf_num)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PK3nZypssKI2"},"source":["# Full training"]},{"cell_type":"code","metadata":{"id":"m6SuOmlPDNw7","scrolled":true},"source":["# TRAIN ALL WIND FARMS AND PREDICT\n","# ================================\n","def train_full(wf_num, nested_run=False) :\n","    with mlflow.start_run(nested=nested_run): \n","        mlflow.log_param('wf',wf_num)\n","\n","        # Extract data\n","        df_wf = utilities.extract_wf_data(df, wf_num)        \n","        \n","        # Train model\n","        t_train, x_train, y_train = utilities.get_train_dataset(df_wf, WINDOW_SIZE)\n","        model, history = train_model(t_train, x_train, y_train, None, None, None)\n","\n","        # Predict on test data\n","        t_test, x_test = utilities.get_test_dataset(df_wf, WINDOW_SIZE)\n","        dataset_test = utilities.get_windowed_dataset(x_test, None, WINDOW_SIZE, BATCH_SIZE, shuffle=False)\n","        y_test_predict = utilities.predict(model, dataset_test, t_test)    \n","        utilities.plot_predictions(t_test, None, y_test_predict, 'test')\n","\n","    return y_test_predict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"67BQ2u3Azlzh","jupyter":{"outputs_hidden":true}},"source":["mlflow.set_experiment('Full training')\n","with mlflow.start_run():\n","    predictions = [train_full(wf_num, nested_run=True) for wf_num in df.WF.unique()]\n","    utilities.save_predictions(predictions)"],"execution_count":null,"outputs":[]}]}