{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7DZa4UUDNw2"
   },
   "source": [
    "# Wind Power forecasting for the day-ahead energy market\n",
    "by Compagnie Nationale du Rhône, ENS Paris & Collège de France\n",
    "\n",
    "<p align=\"center\"><img src=\"https://cap.img.pmdstatic.net/fit/http.3A.2F.2Fprd2-bone-image.2Es3-website-eu-west-1.2Eamazonaws.2Ecom.2Fcap.2F2019.2F10.2F04.2Fea495374-9115-4be7-a91a-e9bc5b305b0b.2Ejpeg/768x432/background-color/ffffff/focus-point/992%2C1086/quality/70/dangereuses-pour-la-sante-peu-ecolo-faut-il-en-finir-avec-les-eoliennes-1352031.jpg\" width=\"600\"/></p>\n",
    "\n",
    "Challenge website: https://challengedata.ens.fr/participants/challenges/34/\n",
    "\n",
    "## Challenge presentation\n",
    "\n",
    "The objective of this challenge is to predict the hourly production of 6 independent wind farms for the day ahead, using several national weather forecasts (NWP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvtF7nQATbmR"
   },
   "outputs": [],
   "source": [
    "# Google Colab config\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "%cd /content/gdrive/MyDrive/wind-power-forecasting-challenge\n",
    "!pip install urllib3==1.25.4 folium==0.2.1 boto3 mlflow mpld3 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 22601,
     "status": "ok",
     "timestamp": 1612551946501,
     "user": {
      "displayName": "Quentin Chateiller",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguKgZaCTK0rxnxTJIqcAU2_SCRshI2HzPX7stG7AY=s64",
      "userId": "11797464397335309536"
     },
     "user_tz": -60
    },
    "id": "hf8u3qX7DNw4"
   },
   "outputs": [],
   "source": [
    "# Load libraires\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import importlib\n",
    "import utilities\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import mpld3\n",
    "import os\n",
    "import pandas as pd\n",
    "cred = pd.read_csv('aws_credentials.csv',index_col=0, squeeze=True)\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = cred.AWS_ACCESS_KEY_ID\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = cred.AWS_SECRET_ACCESS_KEY\n",
    "mlflow.set_tracking_uri(f\"http://{cred.AWS_USERNAME}:{cred.AWS_PASSWORD}@{cred.AWS_URL}\")\n",
    "mlflow.tensorflow.autolog(every_n_iter=1,log_models=False)\n",
    "mpld3.enable_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unrWlVffDNw5"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WV8JmIjrc_wO"
   },
   "outputs": [],
   "source": [
    "# Data parameters\r\n",
    "FORECAST_MEMORY = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZ-PrOMhDNw5"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = utilities.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DqDy19JNDNw6"
   },
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "df = utilities.calculate_best_forecasts(df, FORECAST_MEMORY)\n",
    "df = utilities.interpolate_nans(df)\n",
    "df = utilities.augment_data(df)\n",
    "df = utilities.normalize_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piGHgpwSDNw6"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gYtVmg6WdGjc"
   },
   "outputs": [],
   "source": [
    "# Model parameters\r\n",
    "WINDOW_SIZE = 72  # In hours\r\n",
    "BATCH_SIZE = 2000\r\n",
    "EPOCHS = 10\r\n",
    "UNITS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mF1wTcwTDNw6"
   },
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(t_train, x_train, y_train, t_valid, x_valid, y_valid):\n",
    "\n",
    "    mlflow.log_params({'window_size':WINDOW_SIZE, 'units':UNITS, 'layer_type':'GRU'})\n",
    "    \n",
    "    # Make learning datasets\n",
    "    dataset_train = utilities.get_windowed_dataset(x_train, y_train, WINDOW_SIZE, BATCH_SIZE, shuffle=True)\n",
    "    dataset_valid = utilities.get_windowed_dataset(x_valid, y_valid, WINDOW_SIZE, BATCH_SIZE, shuffle=False) if x_valid is not None else None\n",
    "        \n",
    "    # Define model\n",
    "    model = tf.keras.Sequential([\n",
    "                tf.keras.layers.InputLayer(input_shape=next(iter(dataset_train))[0].shape[1:]),\n",
    "                tf.keras.layers.GRU(UNITS, return_sequences=True),\n",
    "                tf.keras.layers.Dropout(0.6),\n",
    "                tf.keras.layers.GRU(UNITS, return_sequences=True),\n",
    "                tf.keras.layers.Dropout(0.6),\n",
    "                tf.keras.layers.GRU(UNITS),\n",
    "                tf.keras.layers.Dense(1, activation='relu')\n",
    "            ])\n",
    "    model.compile(loss='mse', \n",
    "                  optimizer=tf.keras.optimizers.Adam())\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(dataset_train, \n",
    "                        validation_data=dataset_valid,\n",
    "                        epochs=EPOCHS,\n",
    "                        verbose=1, \n",
    "                        callbacks=[])#tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.00001,patience=30)])\n",
    "    utilities.plot_learning_curves(history)\n",
    "    \n",
    "    # Check predictions\n",
    "    y_train_predict = utilities.predict(model, dataset_train, t_train)\n",
    "    utilities.plot_predictions(t_train, y_train, y_train_predict, 'train')\n",
    "    if dataset_valid is not None :\n",
    "        y_valid_predict = utilities.predict(model, dataset_valid, t_valid)\n",
    "        utilities.plot_predictions(t_valid, y_valid, y_valid_predict, 'valid')\n",
    "            \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7l1P4URCZrUT"
   },
   "source": [
    "# Holdout validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HN6vRa-rdZcl"
   },
   "outputs": [],
   "source": [
    "HOLDOUT_VAL_SPLIT = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08_Y_Us5DNw6"
   },
   "outputs": [],
   "source": [
    "# TRAIN ONLY ONE WIND FARM\n",
    "# ================================\n",
    "def train_holdout_validation(wf_num, nested_run=False) :\n",
    "\n",
    "    with mlflow.start_run(nested=nested_run):    \n",
    "        mlflow.log_params({'wf':wf_num, 'split':HOLDOUT_VAL_SPLIT})\n",
    "\n",
    "        # Extract wf data\n",
    "        df_wf = utilities.extract_wf_data(df, wf_num)\n",
    "        \n",
    "        # Train\n",
    "        t_train, x_train, y_train, t_valid, x_valid, y_valid = utilities.split_holdout_validation(df_wf, HOLDOUT_VAL_SPLIT, WINDOW_SIZE)\n",
    "        model, history = train_model(t_train, x_train, y_train, t_valid, x_valid, y_valid)\n",
    "            \n",
    "    return model, history    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50QVcEqgzlzc"
   },
   "outputs": [],
   "source": [
    "# Train one wind farm\n",
    "mlflow.set_experiment('holdout_validation')\n",
    "model, history = train_holdout_validation(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rY_7A48AOMCF"
   },
   "outputs": [],
   "source": [
    "# Train all wind farms\n",
    "mlflow.set_experiment('holdout_validation')\n",
    "with mlflow.start_run() :\n",
    "    for wf_num in df.WF.unique(): \n",
    "        train_holdout_validation(wf_num, nested_run = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4xRxSDtv0e3"
   },
   "source": [
    "# Forward chaining validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JoLW8rJ7d-Fg"
   },
   "outputs": [],
   "source": [
    "# Forward chaining parameters\r\n",
    "FC_VAL_NB = 4\r\n",
    "FC_VAL_SIZE = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qdriGb82v0e3"
   },
   "outputs": [],
   "source": [
    "def train_forward_chaining_validation(wf_num):\n",
    "\n",
    "    # Extract wf data\n",
    "    df_wf = utilities.extract_wf_data(df, wf_num)\n",
    "    \n",
    "    # Train models\n",
    "    metrics = []\n",
    "    datas = utilities.split_forward_chaining_validation(df_wf, FC_VAL_SIZE, FC_VAL_NB, WINDOW_SIZE)\n",
    "    for (t_train, x_train, y_train, t_valid, x_valid, y_valid) in datas :\n",
    "        with mlflow.start_run(nested=True) :\n",
    "            model, history = train_model(t_train, x_train, y_train, t_valid, x_valid, y_valid)\n",
    "            metrics.append(history.history)\n",
    "    \n",
    "    # Calculate mean and std errors\n",
    "    metrics = utilities.get_mean_std_metrics(metrics)\n",
    "    mlflow.log_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKdYEe9Ox1k_"
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment('forward_chaining_validation')\n",
    "for wf_num in df.WF.unique():\n",
    "    with mlflow.start_run():    \n",
    "        mlflow.log_params({'wf':wf_num,'valid_size':FC_VAL_SIZE,'nb_valid':FC_VAL_NB, 'nlayers':3, \n",
    "                        'layer_type':'GRU','units':UNITS,'epochs':EPOCHS, 'parent':True})\n",
    "        train_forward_chaining_validation(wf_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jC0ea6kQgr1J"
   },
   "outputs": [],
   "source": [
    "wf_num = 4\r\n",
    "mlflow.set_experiment('forward_chaining_validation')\r\n",
    "for UNITS in [32,64] :\r\n",
    "    with mlflow.start_run() :\r\n",
    "        mlflow.log_params({'wf':wf_num,'valid_size':FC_VAL_SIZE,'nb_valid':FC_VAL_NB, 'nlayers':1, \r\n",
    "                           'layer_type':'GRU', 'units':UNITS, 'epochs':EPOCHS, 'parent':True })\r\n",
    "        train_forward_chaining_validation(wf_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PK3nZypssKI2"
   },
   "source": [
    "# Full training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m6SuOmlPDNw7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TRAIN ALL WIND FARMS AND PREDICT\n",
    "# ================================\n",
    "def train_full(wf_num, nested_run=False) :\n",
    "    with mlflow.start_run(nested=nested_run): \n",
    "        mlflow.log_param('wf',wf_num)\n",
    "\n",
    "        # Extract data\n",
    "        df_wf = utilities.extract_wf_data(df, wf_num)        \n",
    "        \n",
    "        # Train model\n",
    "        t_train, x_train, y_train = utilities.get_train_dataset(df_wf, WINDOW_SIZE)\n",
    "        model, history = train_model(t_train, x_train, y_train, None, None, None)\n",
    "\n",
    "        # Predict on test data\n",
    "        t_test, x_test = utilities.get_test_dataset(df_wf, WINDOW_SIZE)\n",
    "        dataset_test = utilities.get_windowed_dataset(x_test, None, WINDOW_SIZE, BATCH_SIZE, shuffle=False)\n",
    "        y_test_predict = utilities.predict(model, dataset_test, t_test)    \n",
    "        utilities.plot_predictions(t_test, None, y_test_predict, 'test')\n",
    "\n",
    "    return y_test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "67BQ2u3Azlzh",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment('Full training')\n",
    "with mlflow.start_run():\n",
    "    predictions = [train_full(wf_num, nested_run=True) for wf_num in df.WF.unique()]\n",
    "    utilities.save_predictions(predictions)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lstm_testsetval.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "wind-power-forecasting-challenge",
   "language": "python",
   "name": "wind-power-forecasting-challenge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
